{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'e:\\\\Python\\\\python_code\\\\KnowledgeMeme\\\\SAOandKM'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from jieba.analyse import *\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "mypath=os.getcwd()\n",
    "mypath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.KM_A的抽取\n",
    "- 对摘要进行分词\n",
    "- 两年一个时间段，对时间进行切片\n",
    "- 分好的词与词典对比，不在词典中就删除\n",
    "- 每一个词对应一个知识元\n",
    "- 通过TF-idf计算出每个时间段的知识元的权重\n",
    "- 可视化展示，随着时间的变化知识元的变化情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir=mypath + \"\\dictionary\\Dir.txt\" #词典，60503条\n",
    "Fpath=mypath + \"\\dictionary\\StopWords.txt\" #停用词，4652条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.划分时间段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['2000-2001','2002-2003','2004-2005','2006-2007','2008-2009','2010-2011','2012-2013','2014-2015','2016-2017','2018-2019']\n",
    "\n",
    "#划分时间段\n",
    "def Period(LISdata):\n",
    "    Summary=LISdata[['年','题名','摘要']]\n",
    "    Summary.sort_values(\"年\",inplace=True)\n",
    "    labels1=labels\n",
    "    Summary['时间段']=pd.cut(Summary['年'],10,labels=labels1)\n",
    "    return Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年</th>\n",
       "      <th>题名</th>\n",
       "      <th>摘要</th>\n",
       "      <th>时间段</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>2000</td>\n",
       "      <td>图书馆知识管理管见</td>\n",
       "      <td>知识经济时代的知识管理可分为宏观、中观和微观 3个层次。图书馆知识管理属微观知识管理 ,其主...</td>\n",
       "      <td>2000-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>2000</td>\n",
       "      <td>可持续发展战略对21世纪图书馆发展的启示</td>\n",
       "      <td>结合可持续发展战略的主要思想 ,论述了知识经济时代图书馆走可持续发展之路的重要意义和必然性 ...</td>\n",
       "      <td>2000-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2000</td>\n",
       "      <td>试论数字作品的知识产权保护</td>\n",
       "      <td>作为信息社会发展原动力的数字技术的不断发展和普及 ,导致了一系列数字作品的出现 ,进而给现行...</td>\n",
       "      <td>2000-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>2000</td>\n",
       "      <td>国产图书馆自动化集成系统比较研究</td>\n",
       "      <td>文章选取了四种国产图书馆自动化集成系统 ,从它们的系统功能、技术特点以及数据处理几方面进行比...</td>\n",
       "      <td>2000-2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>2000</td>\n",
       "      <td>企业反竞争情报研究</td>\n",
       "      <td>The concept,content and methods of defensive c...</td>\n",
       "      <td>2000-2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         年                    题名  \\\n",
       "8697  2000             图书馆知识管理管见   \n",
       "5455  2000  可持续发展战略对21世纪图书馆发展的启示   \n",
       "2134  2000         试论数字作品的知识产权保护   \n",
       "3290  2000      国产图书馆自动化集成系统比较研究   \n",
       "1569  2000             企业反竞争情报研究   \n",
       "\n",
       "                                                     摘要        时间段  \n",
       "8697  知识经济时代的知识管理可分为宏观、中观和微观 3个层次。图书馆知识管理属微观知识管理 ,其主...  2000-2001  \n",
       "5455  结合可持续发展战略的主要思想 ,论述了知识经济时代图书馆走可持续发展之路的重要意义和必然性 ...  2000-2001  \n",
       "2134  作为信息社会发展原动力的数字技术的不断发展和普及 ,导致了一系列数字作品的出现 ,进而给现行...  2000-2001  \n",
       "3290  文章选取了四种国产图书馆自动化集成系统 ,从它们的系统功能、技术特点以及数据处理几方面进行比...  2000-2001  \n",
       "1569  The concept,content and methods of defensive c...  2000-2001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LISdata=pd.read_csv(mypath+ '\\data\\LIS_PAPERS.csv')\n",
    "ZYFC=Period(LISdata)\n",
    "ZYFC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词\n",
    "def Participle(Summary):\n",
    "    Summary['摘要']=Summary['摘要'].astype(str)\n",
    "    Fpath1=Fpath\n",
    "    Dir1=Dir\n",
    "    stopwords = [line.strip() for line in open(Fpath1, 'r', encoding='utf-8').readlines()] \n",
    "    jieba.load_userdict(Dir1)\n",
    "    Summary['摘要_分词'] = Summary['摘要'].apply(lambda y: \",\".join([z for z in list(jieba.cut(y)) if z not in stopwords]))\n",
    "    return Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\2\\jieba.cache\n",
      "Loading model cost 2.172 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>年</th>\n",
       "      <th>题名</th>\n",
       "      <th>摘要</th>\n",
       "      <th>时间段</th>\n",
       "      <th>摘要_分词</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>2000</td>\n",
       "      <td>图书馆知识管理管见</td>\n",
       "      <td>知识经济时代的知识管理可分为宏观、中观和微观 3个层次。图书馆知识管理属微观知识管理 ,其主...</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>知识经济时代,知识管理,分为,宏观,中观,微观, ,层次,图书馆知识管理,属,微观,知识管理...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5455</th>\n",
       "      <td>2000</td>\n",
       "      <td>可持续发展战略对21世纪图书馆发展的启示</td>\n",
       "      <td>结合可持续发展战略的主要思想 ,论述了知识经济时代图书馆走可持续发展之路的重要意义和必然性 ...</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>可持续发展,战略,思想, ,论述,知识经济时代,图书馆,走,可持续发展,之路,意义,必然性,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2000</td>\n",
       "      <td>试论数字作品的知识产权保护</td>\n",
       "      <td>作为信息社会发展原动力的数字技术的不断发展和普及 ,导致了一系列数字作品的出现 ,进而给现行...</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>信息社会,发展,原动力,数字技术,发展,普及, ,导致,一系列,数字作品, ,现行,知识产权...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>2000</td>\n",
       "      <td>国产图书馆自动化集成系统比较研究</td>\n",
       "      <td>文章选取了四种国产图书馆自动化集成系统 ,从它们的系统功能、技术特点以及数据处理几方面进行比...</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>文章,选取,四种,国产,图书馆自动化集成系统, ,系统功能,技术,数据处理,比较分析, ,概...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>2000</td>\n",
       "      <td>企业反竞争情报研究</td>\n",
       "      <td>The concept,content and methods of defensive c...</td>\n",
       "      <td>2000-2001</td>\n",
       "      <td>The, ,concept,content, , ,methods, , ,defensiv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         年                    题名  \\\n",
       "8697  2000             图书馆知识管理管见   \n",
       "5455  2000  可持续发展战略对21世纪图书馆发展的启示   \n",
       "2134  2000         试论数字作品的知识产权保护   \n",
       "3290  2000      国产图书馆自动化集成系统比较研究   \n",
       "1569  2000             企业反竞争情报研究   \n",
       "\n",
       "                                                     摘要        时间段  \\\n",
       "8697  知识经济时代的知识管理可分为宏观、中观和微观 3个层次。图书馆知识管理属微观知识管理 ,其主...  2000-2001   \n",
       "5455  结合可持续发展战略的主要思想 ,论述了知识经济时代图书馆走可持续发展之路的重要意义和必然性 ...  2000-2001   \n",
       "2134  作为信息社会发展原动力的数字技术的不断发展和普及 ,导致了一系列数字作品的出现 ,进而给现行...  2000-2001   \n",
       "3290  文章选取了四种国产图书馆自动化集成系统 ,从它们的系统功能、技术特点以及数据处理几方面进行比...  2000-2001   \n",
       "1569  The concept,content and methods of defensive c...  2000-2001   \n",
       "\n",
       "                                                  摘要_分词  \n",
       "8697  知识经济时代,知识管理,分为,宏观,中观,微观, ,层次,图书馆知识管理,属,微观,知识管理...  \n",
       "5455  可持续发展,战略,思想, ,论述,知识经济时代,图书馆,走,可持续发展,之路,意义,必然性,...  \n",
       "2134  信息社会,发展,原动力,数字技术,发展,普及, ,导致,一系列,数字作品, ,现行,知识产权...  \n",
       "3290  文章,选取,四种,国产,图书馆自动化集成系统, ,系统功能,技术,数据处理,比较分析, ,概...  \n",
       "1569  The, ,concept,content, , ,methods, , ,defensiv...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pa=Participle(ZYFC)\n",
    "Pa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.按时间段切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "时间段\n",
       "2000-2001    知识经济时代,知识管理,分为,宏观,中观,微观, ,层次,图书馆知识管理,属,微观,知识管理...\n",
       "2002-2003    论述,数字图书馆,传统图书馆,关系,预测,数字图书馆,发展方向,指出,数字图书馆建设,中应 ...\n",
       "2004-2005    文章,分析,大学生,信息素质教育,现实意义,主要内容, ,教育,途径,探讨 分析,供应链,供...\n",
       "2006-2007    本文,虚拟参考咨询服务,动力系统,模式,分析,图书馆,效用,最大化,虚拟参考咨询,动力源,技...\n",
       "2008-2009    本文,综合,学术界,看法,基础,提出,网络,信息服务质量,指标,信息服务网,站,对象,实证研...\n",
       "2010-2011    发表,2000,2008,年间,代表,引文分析,研究进展,情报学文献,评述,勾勒,出,引文分...\n",
       "2012-2013    面对,信息环境,用户,获取信息,手段,变化,图书馆员,致力于,利用,现代化,信息技术,读者,...\n",
       "2014-2015    本文,构建,复杂网络,模块化,模型,引入,中心性,度量,集聚,系数,两类,系统化,社会,网络...\n",
       "2016-2017    知识图谱,快速,兴起,发展,跨学科研究,领域,国内外,学科,间,发展轨迹,研究重点,总体,差...\n",
       "2018-2019    目的, ,意义,大数据,背景,构建,合适,用户行为模型,海量,行为日志,数据,提供,个性化服...\n",
       "Name: 摘要_分词, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#切片\n",
    "def ab(df):\n",
    "    return' '.join(df.values)\n",
    "\n",
    "Summary3 = Pa.groupby(['时间段'])['摘要_分词'].apply(ab)\n",
    "Summary3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.知识元遍历词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#知识元遍历词典\n",
    "def Traverse(Summary3):     #Summary3是按时间切片后的数据\n",
    "    Dir2=Dir    \n",
    "    f = open(Dir2,encoding='utf-8')\n",
    "    Dir2=f.read().split(\"\\n\")\n",
    "    key_words =[] \n",
    "    for i in Summary3 :\n",
    "        LI = i.split(\",\")\n",
    "        key_words.append(LI)\n",
    "    for j in key_words :\n",
    "        for x in j[:] :\n",
    "            if x not in Dir2 :\n",
    "                j.remove(x)\n",
    "    return key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traverse=Traverse(Summary3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.知识元权重随时间变化\n",
    "- 取出TFidf前1000的关键词作为KM_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#知识元权重随时间变化\n",
    "def TFidfWeights(key_words):\n",
    "    key_words3 =[] \n",
    "    for i in key_words :\n",
    "        words3=jieba.analyse.extract_tags(str(i), topK=1000)#返回tfidf值排前1000的关键词\n",
    "        key_words3.append(words3)\n",
    "        # print(words3)\n",
    "    key_words3[0]\n",
    "    key_words_df4 = pd.DataFrame(key_words3).T\n",
    "    key_words_df4.columns=labels\n",
    "    return key_words_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFdf=TFidfWeights(traverse)\n",
    "\n",
    "# TFdf.to_csv(mypath+ '\\generated_data\\KM_A(TFIDF1000).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000-2001</th>\n",
       "      <th>2002-2003</th>\n",
       "      <th>2004-2005</th>\n",
       "      <th>2006-2007</th>\n",
       "      <th>2008-2009</th>\n",
       "      <th>2010-2011</th>\n",
       "      <th>2012-2013</th>\n",
       "      <th>2014-2015</th>\n",
       "      <th>2016-2017</th>\n",
       "      <th>2018-2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "      <td>图书馆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>数字图书馆</td>\n",
       "      <td>数字图书馆</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "      <td>分析</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>智慧图书馆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>知识管理</td>\n",
       "      <td>分析</td>\n",
       "      <td>探讨</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>研究</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>分析</td>\n",
       "      <td>文章</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>分析</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>我国</td>\n",
       "      <td>研究</td>\n",
       "      <td>研究</td>\n",
       "      <td>高校图书馆</td>\n",
       "      <td>研究</td>\n",
       "      <td>研究</td>\n",
       "      <td>构建</td>\n",
       "      <td>高校图书馆</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>参考文献</td>\n",
       "      <td>探讨</td>\n",
       "      <td>研究</td>\n",
       "      <td>探讨</td>\n",
       "      <td>我国</td>\n",
       "      <td>公共图书馆</td>\n",
       "      <td>构建</td>\n",
       "      <td>大数据</td>\n",
       "      <td>大数据</td>\n",
       "      <td>用户</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2000-2001 2002-2003 2004-2005 2006-2007 2008-2009 2010-2011 2012-2013  \\\n",
       "0       图书馆       图书馆       图书馆       图书馆       图书馆       图书馆       图书馆   \n",
       "1     数字图书馆     数字图书馆        分析        分析        分析        分析        分析   \n",
       "2      知识管理        分析        探讨     高校图书馆     高校图书馆        研究     高校图书馆   \n",
       "3        分析     高校图书馆        我国        研究        研究     高校图书馆        研究   \n",
       "4      参考文献        探讨        研究        探讨        我国     公共图书馆        构建   \n",
       "\n",
       "  2014-2015 2016-2017 2018-2019  \n",
       "0       图书馆       图书馆       图书馆  \n",
       "1        分析     高校图书馆     智慧图书馆  \n",
       "2     高校图书馆        分析        文章  \n",
       "3        研究        构建     高校图书馆  \n",
       "4       大数据       大数据        用户  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.KM_B的抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.从SAO里面抽取KM_B\n",
    "- 1.清洗\n",
    "- 2.~~Subject和Object挑选词频>n(这里设置为3),保留；否则，删除~~\n",
    "- 3.和词典对比，Subject或Action或OBject在词典，保留；否则，删除；~~再去重~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAO清洗\n",
    "def SAO_clean(WJCD):       #WJCD为要导入的数据\n",
    "        #抽取\n",
    "        print('正在清洗SAO数据......')\n",
    "        Abstract=[]\n",
    "        for i in range(len(WJCD)):\n",
    "            pa_p=WJCD.iloc[i]\n",
    "            pa_citedpaper=pa_p[2]\n",
    "            # print('第',i,'篇文章的sao：',pa_citedpaper)\n",
    "            pa_citedpaper_1 = pa_citedpaper.split(\"$\")\n",
    "            # print(len(pa_citedpaper_1))\n",
    "            for idx in range(0, len(pa_citedpaper_1)):\n",
    "                Abstract.append([pa_citedpaper_1[idx]])\n",
    "        print('抽取成功！')\n",
    "        #分离\n",
    "        Abstract_clean = []\n",
    "        for i in Abstract :\n",
    "            for j in i :\n",
    "                # print(j)\n",
    "                # gjc1 = j.split(\"#\")\n",
    "                gjc1=j.split('#')\n",
    "                # print(gjc1)\n",
    "                Abstract_clean.append(gjc1)\n",
    "        print('分离成功！')\n",
    "        #去重\n",
    "        Abstract_clean = [i for i in Abstract_clean if i !=[' ']]\n",
    "        print('去重成功！')\n",
    "        return Abstract_clean\n",
    "\n",
    "# #筛选出高频词\n",
    "# def HighFrequencyWords(SAOlist,WF):  #SAOlist为清洗后的SAO,WF为输入的词频率\n",
    "#     print('正在筛选SAO高频词......')\n",
    "#     Subject=[]\n",
    "#     Object=[]\n",
    "#     for i in range(0,len(SAOlist)) :        #提取Subject和Object高频词\n",
    "#         Subject.append(SAOlist[i][0])\n",
    "#         Object.append(SAOlist[i][2])\n",
    "#     # print(Subject)\n",
    "#     cs = Counter(Subject)\n",
    "#     co = Counter(Object)\n",
    "#     print('词频统计成功！')\n",
    "#     f = open(Fpath)\n",
    "#     stopwords=f.read().split(\"\\n\")\n",
    "    \n",
    "#     for sw in stopwords:                    #去除停用词\n",
    "#         del cs[sw]\n",
    "#         del co[sw]\n",
    "#     print('去除停用词成功！')\n",
    "#     Sub=[]\n",
    "#     Obj=[]\n",
    "#     for k,v in cs.items():\n",
    "#             # print(k, '=', v)\n",
    "#             if v >WF :\n",
    "#                 Sub.append(k)\n",
    "#     for k,v in co.items():\n",
    "#             # print(k, '=', v)\n",
    "#             if v >WF :\n",
    "#                 Obj.append(k)\n",
    "#     HighSO=[]            \n",
    "#     for i in range(0,len(SAOlist)) :\n",
    "#         if SAOlist[i][0] in Sub or SAOlist[i][2] in Obj :  #Subject或Object出现频率高就保留\n",
    "#             HighSO.append(SAOlist[i])\n",
    "#     print('筛选出词频大于{name}的词条成功！'.format(name=WF))        \n",
    "#     return HighSO\n",
    "\n",
    "#去除词典中没有的词\n",
    "def NotInDir(SAOlist):     #SAOlist为清理后的三元组\n",
    "        print('正在遍历词典......')\n",
    "        f = open(mypath + \"\\dictionary\\Dir.txt\",encoding='utf-8')\n",
    "        Dir3=f.read().split(\"\\n\")    #Dir为词典\n",
    "        New_SAO=[]\n",
    "        for i in range(0,len(SAOlist)) :\n",
    "            # print(SAO[dr])\n",
    "            if (SAOlist[i][0] in Dir3) and (SAOlist[i][2] in Dir3) : #Subject和Object在词典中就保留\n",
    "                New_SAO.append(SAOlist[i])\n",
    "        print('词典遍历成功！共有{n}条知识基因'.format(n=len(New_SAO)))   \n",
    "        #去重\n",
    "#         New_SAO_clean = []\n",
    "#         for id in New_SAO:\n",
    "#             if id not in New_SAO_clean:\n",
    "#                 New_SAO_clean.append(id)\n",
    "#         print('去重成功！共有{n}条知识基因'.format(n=len(New_SAO_clean)))\n",
    "        return New_SAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1.摘要SAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在清洗SAO数据......\n",
      "抽取成功！\n",
      "分离成功！\n",
      "去重成功！\n",
      "正在遍历词典......\n",
      "词典遍历成功！共有18895条知识基因\n"
     ]
    }
   ],
   "source": [
    "Abstract_sao=pd.read_excel(mypath + \"\\data\\Abstract_sao.xlsx\",sheet_name='Sheet1')\n",
    "ABS_SAO=NotInDir(SAO_clean(Abstract_sao))\n",
    "#注：这里的摘要SAO只用‘或’和词典遍历，没有去重，没有筛选高频词；下同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(ABS_SAO, columns=['subject', 'action', 'object']).to_csv(mypath + '\\generated_data\\KM_B(摘要SAO).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2.参考SAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在清洗SAO数据......\n",
      "抽取成功！\n",
      "分离成功！\n",
      "去重成功！\n",
      "正在遍历词典......\n",
      "词典遍历成功！共有9016条知识基因\n"
     ]
    }
   ],
   "source": [
    "Ref_sao=pd.read_csv(mypath + \"\\data\\paper_referenced_TripleExtraction.csv\")\n",
    "REF_SAO=NotInDir(SAO_clean(Ref_sao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(REF_SAO, columns=['Rsubject', 'Raction', 'Robject']).to_csv(mypath + '\\generated_data\\参考SAO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.3.引用SAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正在清洗SAO数据......\n",
      "抽取成功！\n",
      "分离成功！\n",
      "去重成功！\n",
      "正在遍历词典......\n",
      "词典遍历成功！共有22705条知识基因\n"
     ]
    }
   ],
   "source": [
    "Cit_sao=pd.read_excel(mypath + \"\\data\\paper_cited_TripleExtraction.xlsx\",sheet_name='paper_cited_TripleExtraction')\n",
    "CIT_SAO=NotInDir(SAO_clean(Cit_sao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(CIT_SAO, columns=['Csubject', 'Caction', 'Cobject','none']).to_csv(mypath + '\\generated_data\\引文SAO.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.KM_Final的识别\n",
    "- KM_A(TFIDF1000)和KM_B(摘要SAO)映射\n",
    "- 如果Subject或Action或Object在KM_A中，保留；否则，删除。\n",
    "- 保留下来的就是最终的知识基因"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF1000转化为列表\n",
    "from tkinter import _flatten\n",
    "\n",
    "tfidf1000tolist=list(set(list(_flatten(TFdf.values.tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['摘要', '索引', '信息重组', '图书馆社会化', '知识产权保护', '加权', '读者服务工作', '组织方法', '出版商', '效应']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf1000tolist[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终的摘要知识基因有17149条\n"
     ]
    }
   ],
   "source": [
    "KM_Final=[]\n",
    "for i in range(len(ABS_SAO)) :\n",
    "    if (ABS_SAO[i][0] in tfidf1000tolist) or (ABS_SAO[i][1] in tfidf1000tolist) or (ABS_SAO[i][2] in tfidf1000tolist)  :\n",
    "        KM_Final.append(ABS_SAO[i])\n",
    "        \n",
    "print('最终的摘要知识基因有{}条'.format(len(KM_Final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(KM_Final, columns=['subject', 'action', 'object']).to_csv(mypath + '\\generated_data\\KM_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ea1d30b81493ad4e83832c30fd2d1afdd89257e8ee88b0c08169d2ce4111f838"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}